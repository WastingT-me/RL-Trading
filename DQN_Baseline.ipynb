{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xdlvcrr4Mefq",
        "outputId": "4136c53a-3e0b-4384-87a2-1a46bbbfaab8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (0.2.40)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym) (2.2.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym) (0.0.8)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.31.0)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.9.4)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.2.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.4.4)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.10/dist-packages (from yfinance) (3.17.6)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.12.3)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy pandas matplotlib torch gym yfinance"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Baseline"
      ],
      "metadata": {
        "id": "Vpfe_-T7VZmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from collections import deque\n",
        "import random\n",
        "import yfinance as yf\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "18lHKnliNzXz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download historical stock data"
      ],
      "metadata": {
        "id": "v3sFuPAlPLm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_stock_data(ticker, start_date, end_date):\n",
        "    data = yf.download(ticker, start=start_date, end=end_date)\n",
        "    data.reset_index(inplace=True)\n",
        "    return data"
      ],
      "metadata": {
        "id": "fIZeKBw9N3wt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the Trading Environment"
      ],
      "metadata": {
        "id": "oQi4IfTdPN1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TradingEnv:\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "        self.n_step = len(df)\n",
        "        self.action_space = 3  # Buy, Hold, Sell\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.current_step = 0\n",
        "        self.balance = 10000  # initial balance\n",
        "        self.shares_held = 0\n",
        "        self.total_value = self.balance\n",
        "        self.total_values = []  # To store portfolio values\n",
        "        return self._next_observation()\n",
        "\n",
        "    def _next_observation(self):\n",
        "        return self.df.iloc[self.current_step].drop('Date').values.astype(np.float32)\n",
        "\n",
        "    def step(self, action):\n",
        "        current_price = self.df.iloc[self.current_step]['Close']\n",
        "        reward = 0\n",
        "\n",
        "        if action == 0:  # Buy\n",
        "            self.shares_held += self.balance // current_price\n",
        "            self.balance %= current_price\n",
        "        elif action == 2:  # Sell\n",
        "            self.balance += self.shares_held * current_price\n",
        "            self.shares_held = 0\n",
        "\n",
        "        self.current_step += 1\n",
        "        self.total_value = self.balance + self.shares_held * current_price\n",
        "        self.total_values.append(self.total_value)  # Store portfolio value\n",
        "\n",
        "        if self.current_step >= self.n_step - 1:\n",
        "            done = True\n",
        "        else:\n",
        "            done = False\n",
        "\n",
        "        reward = self.total_value - 10000  # reward based on total portfolio value\n",
        "        return self._next_observation(), reward, done\n",
        "\n",
        "    def render(self):\n",
        "        pass"
      ],
      "metadata": {
        "id": "_lSGdSDIOjVo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the DQN Agent"
      ],
      "metadata": {
        "id": "ZXPsL5nPPQOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DQNAgent(nn.Module):\n",
        "    def __init__(self, state_size, action_size):\n",
        "        super(DQNAgent, self).__init__()\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.memory = deque(maxlen=2000)\n",
        "        self.gamma = 0.95\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_min = 0.01\n",
        "        self.epsilon_decay = 0.995\n",
        "        self.learning_rate = 0.001\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(state_size, 24),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(24, 24),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(24, action_size)\n",
        "        ).to(device)\n",
        "\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
        "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n",
        "        self.loss_fn = nn.MSELoss()\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def act(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return random.randrange(self.action_size)\n",
        "        state = torch.FloatTensor(state).to(device)\n",
        "        act_values = self.model(state)\n",
        "        return torch.argmax(act_values[0]).item()\n",
        "\n",
        "    def replay(self, batch_size):\n",
        "        minibatch = random.sample(self.memory, batch_size)\n",
        "        for state, action, reward, next_state, done in minibatch:\n",
        "            target = reward\n",
        "            if not done:\n",
        "                next_state = torch.FloatTensor(next_state).to(device)\n",
        "                target = reward + self.gamma * torch.max(self.model(next_state)[0]).item()\n",
        "            target_f = self.model(torch.FloatTensor(state).to(device)).detach().cpu().numpy()\n",
        "            target_f[0][action] = target\n",
        "            target_f = torch.FloatTensor(target_f).to(device)\n",
        "            state = torch.FloatTensor(state).to(device)\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(state)\n",
        "            loss = self.loss_fn(outputs, target_f)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            self.scheduler.step(loss)\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "    def load(self, name):\n",
        "        self.model.load_state_dict(torch.load(name))\n",
        "\n",
        "    def save(self, name):\n",
        "        torch.save(self.model.state_dict(), name)"
      ],
      "metadata": {
        "id": "gAjhyCv9OmxS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the DQN Agent"
      ],
      "metadata": {
        "id": "Iq0lyramPWBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Download stock data\n",
        "    ticker = 'AAPL'\n",
        "    start_date = '2020-01-01'\n",
        "    end_date = '2023-01-01'\n",
        "    df = download_stock_data(ticker, start_date, end_date)\n",
        "\n",
        "    env = TradingEnv(df)\n",
        "    state_size = df.shape[1] - 1  # exclude 'Date' column\n",
        "    action_size = 3\n",
        "    agent = DQNAgent(state_size, action_size)\n",
        "    batch_size = 32\n",
        "    episodes = 1000\n",
        "    predicted_values = []\n",
        "\n",
        "    for e in range(episodes):\n",
        "        state = env.reset()\n",
        "        state = np.reshape(state, [1, state_size])\n",
        "        for time in range(env.n_step):\n",
        "            action = agent.act(state)\n",
        "            next_state, reward, done = env.step(action)\n",
        "            reward = reward if not done else -10\n",
        "            next_state = np.reshape(next_state, [1, state_size])\n",
        "            agent.remember(state, action, reward, next_state, done)\n",
        "            state = next_state\n",
        "            if done:\n",
        "                print(f\"episode: {e}/{episodes}, score: {reward}, e: {agent.epsilon:.2}\")\n",
        "                break\n",
        "            if len(agent.memory) > batch_size:\n",
        "                agent.replay(batch_size)\n",
        "        if e % 50 == 0:\n",
        "            agent.save(f\"model_{e}.pth\")\n",
        "\n",
        "        # Store predicted values for the last episode\n",
        "        if e == episodes - 1:\n",
        "            predicted_values = env.total_values\n",
        "\n",
        "    # Extract true values from the dataframe\n",
        "    true_values = df['Close'].values\n",
        "\n",
        "    # Plot true values and predicted values\n",
        "    plt.figure(figsize=(14,7))\n",
        "    plt.plot(true_values, label='True Value')\n",
        "    plt.plot(predicted_values, label='Predicted Value')\n",
        "    plt.xlabel('Time Step')\n",
        "    plt.ylabel('Portfolio Value')\n",
        "    plt.legend()\n",
        "    plt.title(\"True vs Predicted Portfolio Values\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "LHJSf7asOXwP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}